{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0110afd1-1df7-4137-a405-c29bf6278e6b",
   "metadata": {},
   "source": [
    "# Overview of the Gradient Boosted Tree Classifier\n",
    "\n",
    "Gradient Boosting is an ensemble learning method that takes many weak learners (with accuracy slightly above that of a random guess) and combines them sequentially to create a strong learner (model accuracy of >95%) [1]. Gradient boosted decision tree classifiers have already been implemented in SciKitLearn [2], so for validation of our model, we will be comparing its performance with the SciKitLearn implementation utilizing the binary Hastie dataset [3]\n",
    "\n",
    "Advantages:\n",
    "- The steps are intuitive to understand\n",
    "- Versatile - can be used for both classification and regression problems\n",
    "- Highly accurate - gradient boosting methods often top Kaggle competitions for accuracy with structured tabular data [4]\n",
    "- Ensemble approach makes it more robust to outliers in the \n",
    "\n",
    "Disadvantages:\n",
    "- If the hyperparameters aren't tuned carefully, it is easy for the model to overfit the training data\n",
    "- The model can become computationally expensive, as it requires subsequently training multiple weak learners [5]\n",
    "- Like other highly accurate models like neural networks, interpretability may not be the highest\n",
    "\n",
    "### Representation\n",
    "\n",
    "We have chosen to implement Gradient Boosting for a classification problem, using a shallow decision tree as our weak learner. The final model $F(x)$ is therefore built from a sequence of $N$ trees, where each successive tree corrects the predictions from the previous iteration:\n",
    "\n",
    "$F_{N}(x) = F_{0}(x) + \\eta \\sum_{i=1}^{N} h_{i}(x)$ \n",
    "\n",
    "Where:\n",
    "- $F_{0}(x)$ is the initial prediction\n",
    "- $\\eta$ is the learning rate (a value between 0 and 1)\n",
    "- $h_{i}(x)$ is the prediction made by decision tree $i$, trained on the residuals from the previous trees\n",
    "\n",
    "We are not predicting class labels, but are instead predicting pseudo-residuals that will be used to correct the initial prediction. These pseudo-residuals are similar to the residuals in linear regression, in that they are the difference between the true label and the predicted probability of the positive class. As such, we have to modify the weak learner from a decision tree classifier (as implemented in a previous homework) to a decision tree regressor in order to predict the float values.\n",
    "\n",
    "The initial predictions are initialized as the log-odds of the positive class. This is because the optimizer works in the log-odds space rather than probability space. Furthermore, this initialization helps to better handle class imbalance.\n",
    "\n",
    "### Loss\n",
    "\n",
    "As this is a binary classification problem we will be using the Cross-Entropy loss/Log loss as our loss function. The function is:\n",
    "\n",
    "$L(y, \\hat{p}(x)) = -(y \\cdot log(\\hat{p}(x)) + (1-y) \\cdot log(1-\\hat{p}(x)))$\n",
    "\n",
    "Where:\n",
    "- $y$ are the true labels, 1 or 0\n",
    "- $\\hat{p}(x)$ is the probability predictor for the positive class, 1\n",
    "\n",
    "### Optimizer\n",
    "\n",
    "The optimizer is gradient descent on the pseudo-residuals\n",
    "\n",
    "We calculate the pseudo-residuals as the negative gradient of the loss function with respect to the current model prediction:\n",
    "\n",
    "$r_i = -\\frac{\\partial L(y, \\hat{p}(x))}{\\partial F(x)} = y - \\hat{p}(x)$\n",
    "\n",
    "Shallow decision trees are trained on the previous iteration residuals, which are then used to update the prediction until convergence or a given number of iterations elapses. \n",
    "\n",
    "$F_{i+1}(x) = F_{i}(x) + \\eta \\cdot h_{i}(x)$ \n",
    "\n",
    "### Algorithm Pseudocode\n",
    "\n",
    "**inputs:**\n",
    "\n",
    "*training set:* $S = (x_1, y_1), ... , (x_m, y_m)$\n",
    "\n",
    "*weak learner: decision tree regressor* $DTR$\n",
    "\n",
    "*number of trees:* $N$\n",
    "\n",
    "*learning rate:* $\\eta$\n",
    "\n",
    "**initialize:**\n",
    "\n",
    "*set initial predictions as log-odds of the positive class:* $F_{0}(x) = logit(p_{y=1}) = log(\\frac{p_{y=1}}{1-p_{y=1}})$ \n",
    "\n",
    "**for** $i = 0, ...,N-1:$\n",
    "\n",
    "*compute the residuals:* $r_i = -\\frac{\\partial L(y, \\hat{p}_{i}(x))}{\\partial F_{i}(x)} = y - \\hat{p}_{i}(x)$\n",
    "\n",
    "*train a weak learner with residuals as targets:* $h_{i}(x) = DTR(F_{i}(x), S)$\n",
    "\n",
    "*update the model:* $F_{i+1}(x) = F_{i}(x) + \\eta \\cdot h_{i}(x)$\n",
    "\n",
    "**output:** \n",
    "\n",
    "*the predictions* $\\hat{y} = argmax(F_{N}(x))$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128a2637-8438-445a-8925-359496904aa3",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fa765c1-b06d-4a46-85fa-61fe2cfeac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def cal_mse(y):\n",
    "    if len(y) == 0:\n",
    "        return 0\n",
    "    \n",
    "    mean = np.mean(y)\n",
    "\n",
    "    return np.mean((y - mean) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7c370a-1abc-445c-849c-6fa76015e3d0",
   "metadata": {},
   "source": [
    "### Weak Learner: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a57cfae-68ef-47aa-b535-44b567bfcf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, left=None, right=None, depth=0, index_split_on=0, isleaf=False, threshold=None, value=None):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.depth = depth\n",
    "        self.index_split_on = index_split_on\n",
    "        self.isleaf = isleaf\n",
    "        self.threshold = threshold\n",
    "\n",
    "        self.value = value\n",
    "        self.leaf_id = None\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, X, y, max_depth=40, min_samples_split=2, min_samples_leaf=1):\n",
    "        \n",
    "        self.average_value = np.mean(y)\n",
    "        self.max_depth = max_depth\n",
    "        self.root = Node(value=self.average_value)\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        indices = list(range(1, X.shape[1]+1))\n",
    "        self.leaf_id_counter = 1\n",
    "        self.value = []\n",
    "        self._split_recurs(self.root, X, y, indices)\n",
    "        \n",
    "    def predict(self, X):\n",
    "\n",
    "        predictions = []\n",
    "        for i in range(X.shape[0]):\n",
    "            row = X[i,:]\n",
    "            predictions.append(self._predict_recurs(self.root, row))\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict_recurs(self, node, row):\n",
    "\n",
    "        if node.isleaf or node.index_split_on == 0:\n",
    "            return node.value\n",
    "\n",
    "        if row[node.index_split_on-1] <= node.threshold:\n",
    "            return self._predict_recurs(node.left, row)\n",
    "        \n",
    "        else:\n",
    "            return self._predict_recurs(node.right, row)\n",
    "        \n",
    "\n",
    "    def _is_terminal(self, node, X, y, indices):\n",
    "\n",
    "        node.isleaf = False\n",
    "        node.value = np.mean(y)\n",
    "\n",
    "        # Terminate if fewer than `min_samples_split`\n",
    "        if len(y) < self.min_samples_split:\n",
    "            node.isleaf = True\n",
    "\n",
    "        # Terminate if fewer than `min_samples_leaf` would remain in a split\n",
    "        if len(y) > 0 and len(y) <= self.min_samples_leaf:\n",
    "            node.isleaf = True\n",
    "\n",
    "        if len(indices) == 0:\n",
    "            node.isleaf = True\n",
    "        \n",
    "        if len(set(y)) == 1:\n",
    "            node.isleaf = True\n",
    "\n",
    "        if node.depth == self.max_depth:\n",
    "            node.isleaf = True\n",
    "\n",
    "        if node.isleaf == True:\n",
    "            node.leaf_id = self.leaf_id_counter\n",
    "            self.leaf_id_counter += 1\n",
    "            self.value.append(node.value)\n",
    "\n",
    "        return node.isleaf, node.value\n",
    "\n",
    "    def find_threshold(self, X, y, mse, indices):\n",
    "        # find the best index and threshold value for the selected index\n",
    "        best_mse = mse\n",
    "        best_idx = None\n",
    "        best_thresh = None\n",
    "\n",
    "        for idx in indices:\n",
    "            #thresholds = np.unique(X[:, idx-1])\n",
    "            #thresholds = np.linspace(min(X[:,idx-1])/2, max(X[:,idx-1])*2, 10000)\n",
    "            sorted_X = np.sort(X[:,idx-1])\n",
    "            thresholds = (sorted_X[:-1] + sorted_X[1:])/2\n",
    "            for threshold in thresholds:\n",
    "                \n",
    "                left_idx = X[:, idx-1] <= threshold\n",
    "                right_idx = X[:, idx-1] > threshold\n",
    "\n",
    "                # Check `min_samples_leaf` condition\n",
    "                if sum(left_idx) < self.min_samples_leaf or sum(right_idx) < self.min_samples_leaf:\n",
    "                    mse = float('inf')\n",
    "                else:\n",
    "                    mse = cal_mse(y[left_idx])+cal_mse(y[right_idx])\n",
    "\n",
    "                if mse < best_mse:\n",
    "                    best_mse = mse\n",
    "                    best_idx = idx\n",
    "                    best_thresh = threshold\n",
    "\n",
    "        return best_idx, best_thresh\n",
    "\n",
    "    def _split_recurs(self, node, X, y, indices):\n",
    "\n",
    "        node.isleaf, node.value = self._is_terminal(node, X, y, indices)\n",
    "\n",
    "        mse = cal_mse(y)\n",
    "\n",
    "        if not node.isleaf:\n",
    "                \n",
    "            best_idx, best_thresh = self.find_threshold(X, y, mse, indices)\n",
    "            \n",
    "            if best_idx == None:\n",
    "                node.isleaf = True\n",
    "                node.value = np.mean(y)\n",
    "                return\n",
    "\n",
    "            node.threshold = best_thresh\n",
    "            node.index_split_on = best_idx\n",
    "\n",
    "            left_idx = X[:, best_idx-1] <= best_thresh\n",
    "            right_idx = X[:, best_idx-1] > best_thresh\n",
    "\n",
    "            left_X, left_y = X[left_idx], y[left_idx]\n",
    "            right_X, right_y = X[right_idx], y[right_idx]\n",
    "\n",
    "            left_child = Node(depth=node.depth + 1)\n",
    "            right_child = Node(depth=node.depth + 1)\n",
    "            \n",
    "            node.left = left_child\n",
    "            node.right = right_child\n",
    "            \n",
    "            self._split_recurs(left_child, left_X, left_y, indices)\n",
    "            self._split_recurs(right_child, right_X, right_y, indices)\n",
    "\n",
    "    \n",
    "    def apply(self, X):\n",
    "        leaf_indices = []\n",
    "        for i in range(X.shape[0]):\n",
    "            row = X[i,:]\n",
    "            leaf_indices.append(self._apply_recurs(self.root, row))\n",
    "        return np.array(leaf_indices)\n",
    "\n",
    "    def _apply_recurs(self, node, row):\n",
    "        if node.isleaf:\n",
    "            return node.leaf_id  # Return the unique leaf ID\n",
    "        \n",
    "        if row[node.index_split_on - 1] <= node.threshold:\n",
    "            return self._apply_recurs(node.left, row)\n",
    "        else:\n",
    "            return self._apply_recurs(node.right, row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceab23c5",
   "metadata": {},
   "source": [
    "### Weak Learner: Decision Tree (Scikit-Learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e291b33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'mean_squared_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[0;32m     32\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28mprint\u001b[39m(mean_squared_error(y_test, y_pred1))\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(mean_squared_error(y_test, y_pred2))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mean_squared_error' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "X = np.sort(5 * np.random.rand(80, 1), axis=0)\n",
    "y = np.sin(X).ravel() #+ np.random.rand(80) * 0.1\n",
    "\n",
    "# Make predictions\n",
    "X_test = np.arange(0.0, 5.0, 0.01)[:, np.newaxis]\n",
    "y_test = np.sin(X_test).ravel() #+ np.random.rand(500) * 0.1\n",
    "\n",
    "# Create a decision tree regressor\n",
    "regressor = DecisionTreeRegressor(max_depth=4, random_state=0)  # You can adjust the max_depth parameter\n",
    "\n",
    "regressor.fit(X, y)\n",
    "y_pred1 = regressor.predict(X_test)\n",
    "\n",
    "reg = DecisionTree(X, y, max_depth=4)\n",
    "y_pred2 = reg.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.scatter(X, y, s=20, edgecolor=\"black\", c=\"darkorange\", label=\"data\")\n",
    "plt.plot(X_test, y_pred1, color=\"red\", label=\"scikit-learn\", linewidth=1)\n",
    "plt.plot(X_test, y_pred2, color=\"cornflowerblue\", label=\"current\", linewidth=1)\n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"target\")\n",
    "plt.title(\"Decision Tree Regression\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(mean_squared_error(y_test, y_pred1))\n",
    "print(mean_squared_error(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dfcf767",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "    \n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None\n",
    "\n",
    "\n",
    "# Decision Tree Regressor Class\n",
    "class RegressionTree:\n",
    "    def __init__(self, n_feats = None, max_depth = 100, min_samples_split = 2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None ,\n",
    "                 random_state=None ,max_leaf_nodes=None, min_impurity_decrease=0.0, ccp_alpha=0.0):\n",
    "        \n",
    "        self.root = None\n",
    "        self.n_feats = n_feats\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        self.n_feats = X.shape[1] if not self.n_feats else min(self.n_feats, X.shape[1])\n",
    "        self.col = list(X.columns)\n",
    "        self.root = self.growTree(X, Y)\n",
    "\n",
    "    def growTree(self, X, Y, depth = 0):\n",
    "        \n",
    "        df = X.copy()\n",
    "        df['y'] = Y\n",
    "        \n",
    "        ymean = np.mean(Y)\n",
    "        \n",
    "        self.mse = self.get_mse(Y, ymean)\n",
    "        \n",
    "        n_sample, n_feature = X.shape\n",
    "        \n",
    "        # stopping criteria\n",
    "        if (depth >= self.max_depth or n_sample <= self.min_samples_split):\n",
    "            leaf_value = np.mean(Y)\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        feats_idxs = list(X.columns)\n",
    "\n",
    "        best_feat, best_thresh = self.best_criteria(X, Y, feats_idxs)\n",
    "\n",
    "        left_df, right_df = df[df[best_feat]<=best_thresh].copy(), df[df[best_feat]>best_thresh].copy()\n",
    "\n",
    "        left = self.growTree(left_df.drop('y', axis=1), left_df['y'].values.tolist(), depth+1)\n",
    "        right = self.growTree(right_df.drop('y', axis=1), right_df['y'].values.tolist(), depth+1)\n",
    "\n",
    "        return Node(best_feat, best_thresh, left, right)\n",
    "    \n",
    "    \n",
    "    # find out best criteria\n",
    "    def best_criteria(self, X, Y, feats_idxs):\n",
    "        \n",
    "        df = X.copy()\n",
    "        \n",
    "        df['y'] = Y\n",
    "        \n",
    "        mse_base = self.mse\n",
    "        \n",
    "        best_feature = None\n",
    "        best_thresh = None\n",
    "        \n",
    "        for feat in feats_idxs:\n",
    "            \n",
    "            xdf = df.sort_values(feat)\n",
    "            \n",
    "            x_mean = self.moving_average(xdf[feat], 2)\n",
    "\n",
    "            for value in x_mean:\n",
    "                left_y = xdf[xdf[feat] < value]['y'].values\n",
    "                right_y = xdf[xdf[feat] >= value]['y'].values\n",
    "                \n",
    "                left_mean = 0\n",
    "                right_mean = 0\n",
    "                if len(left_y) > 0:\n",
    "                    left_mean = np.mean(left_y)\n",
    "                if len(right_y) > 0:\n",
    "                    right_mean = np.mean(right_y)\n",
    "                \n",
    "                res_left = left_y - left_mean\n",
    "                res_right = right_y - right_mean\n",
    "                \n",
    "                r = np.concatenate((res_left, res_right), axis=None)\n",
    "                \n",
    "                n = len(r)\n",
    "\n",
    "                r = r ** 2\n",
    "                r = np.sum(r)\n",
    "                mse_split = r / n\n",
    "                \n",
    "                if mse_split < mse_base:\n",
    "                    mse_base = mse_split\n",
    "                    best_feature = feat\n",
    "                    best_thresh = value\n",
    "                    \n",
    "        return (best_feature, best_thresh)\n",
    "    \n",
    "    def get_mse(self, y_true, y_hat):\n",
    "        n = len(y_true)\n",
    "        \n",
    "        r = y_true - y_hat\n",
    "        \n",
    "        r = r ** 2\n",
    "        \n",
    "        r = np.sum(r)\n",
    "        \n",
    "        return r / n\n",
    "    \n",
    "    def moving_average(self, x:np.array, window : int):\n",
    "        return np.convolve(x, np.ones(window), 'valid') / window \n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = X.to_numpy().tolist()\n",
    "        \n",
    "        return np.array([self.traverse_tree(x, self.root) for x in X])\n",
    "\n",
    "    def traverse_tree(self, x, node):\n",
    "       \n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        \n",
    "        fr = node.feature\n",
    "        index = self.col.index(fr)\n",
    "\n",
    "        if x[index] <= node.threshold:\n",
    "            return self.traverse_tree(x, node.left)\n",
    "        \n",
    "        return self.traverse_tree(x, node.right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec365e2-4574-450a-ae53-27d493847b7b",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "884883fe-0a0a-48f0-ae38-958a71b51b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GBDTC:\n",
    "    def __init__(self, n_estimators=2, learning_rate=0.1, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.init_val = None\n",
    "        self.trees = None\n",
    "        self.gamma_value = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # X: 2D numpy array for input variables\n",
    "        # y: 1D numpy array for output variables\n",
    "        prob = np.zeros([self.n_estimators+1,X.shape[0]])\n",
    "        gamma = np.zeros([self.n_estimators,X.shape[0]])\n",
    "        self.gamma_value = np.zeros([self.n_estimators,X.shape[0]])\n",
    "        F = np.zeros((self.n_estimators+1,X.shape[0]))\n",
    "\n",
    "        self.init_val = np.log(sum(y==1)/(X.shape[0]-sum(y==1)))\n",
    "\n",
    "        prob[0,:] = np.full(X.shape[0], self.init_val)\n",
    "        F[0,:] = np.full(X.shape[0], np.exp(self.init_val)/(1+np.exp(self.init_val)))\n",
    "\n",
    "        self.residuals = np.zeros((self.n_estimators,X.shape[0]))\n",
    "        self.trees = []\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "\n",
    "            # calculate the residual\n",
    "            self.residuals[i] = y-F[i,:]\n",
    "\n",
    "            # tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            # tree.fit(X, self.residuals[i])\n",
    "            \n",
    "            # self.trees.append(tree)\n",
    "            # tree = tree.tree_\n",
    "            # leaf_indices=tree.apply(X) # total leaves in a tree [1 2 2 2 2 1]\n",
    "\n",
    "            tree = DecisionTree(X, self.residuals[i], max_depth=self.max_depth)\n",
    "            self.trees.append(tree)\n",
    "            leaf_indices = tree.apply(X)\n",
    "\n",
    "            unique_leaves=np.unique(leaf_indices) # [1 2]\n",
    "\n",
    "            for idx in unique_leaves:\n",
    "                n_leaf = len(leaf_indices[leaf_indices==idx])\n",
    "                p_old = F[i][leaf_indices==idx]\n",
    "                denominator = np.sum(p_old*(1-p_old))\n",
    "                #self.gamma_value[i,idx] = tree.value[idx][0][0]*n_leaf / denominator\n",
    "                self.gamma_value[i,idx] = tree.value[idx-1]*n_leaf / denominator\n",
    "\n",
    "            gamma[i] = [self.gamma_value[i][index] for index in leaf_indices]\n",
    "\n",
    "            prob[i+1,:] =  prob[i] + self.learning_rate * gamma[i]\n",
    "            F[i+1,:] = np.array([np.exp(prob_elem)/(np.exp(prob_elem)+1) for prob_elem in prob[i+1,:]])\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        prob = np.zeros([self.n_estimators+1,X.shape[0]])\n",
    "        gamma = np.zeros([self.n_estimators,X.shape[0]])\n",
    "        F = np.zeros((self.n_estimators+1,X.shape[0]))\n",
    "\n",
    "        prob[0,:] = np.full(X.shape[0], self.init_val)\n",
    "        F[0,:] = np.full(X.shape[0], np.exp(self.init_val)/(1+np.exp(self.init_val)))\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "\n",
    "            tree = self.trees[i]\n",
    "            leaf_indices = tree.apply(X)\n",
    "\n",
    "            gamma[i] = [self.gamma_value[i,index] for index in leaf_indices]\n",
    "\n",
    "            prob[i+1,:] =  prob[i] + self.learning_rate * gamma[i]\n",
    "            F[i+1,:] = np.array([np.exp(prob_elem)/(np.exp(prob_elem)+1) for prob_elem in prob[i+1,:]])\n",
    "\n",
    "        predictions = (F[self.n_estimators]>0.5) * 1.0\n",
    "\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203a9a9a-e1f7-4122-b1f9-92ab6636b14c",
   "metadata": {},
   "source": [
    "# Check Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43d0672",
   "metadata": {},
   "source": [
    "### Unit test?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66feb90",
   "metadata": {},
   "source": [
    "### Model Comparison with the Gradient Boosting Classifier from Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "878bb373-b599-44e0-ab69-0952c6d36303",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1268500302.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    '''\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "X, y = make_hastie_10_2(random_state=0)\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.float32)\n",
    "X_train, X_test = X[:2000], X[2000:,:]\n",
    "y_train, y_test = y[:2000], y[2000:]\n",
    "\n",
    "\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=4, learning_rate=0.1,\n",
    "    max_depth=2).fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = clf.predict(X_test)\n",
    "accuracy1 = np.sum(y_test==y_pred1)/len(y_test)\n",
    "\n",
    "y_train[y_train==-1] = 0\n",
    "y_test[y_test==-1] = 0\n",
    "\n",
    "model2 = GBDTC(n_estimators=4,\n",
    "              learning_rate=0.1,\n",
    "              max_depth=2)\n",
    "\n",
    "model2.fit(X_train,y_train)\n",
    "y_pred2 = model2.predict(X_test)\n",
    "accuracy2 = np.sum(y_test==y_pred2)/len(y_test)\n",
    "\n",
    "\n",
    "print(f'accuracy1={accuracy1}')\n",
    "print(f'accuracy2={accuracy2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc5566cd-8900-4ffb-9eb4-3e02fef5d97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import numpy as np\n",
    "#from GBDTC import cal_mse, DecisionTree\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "def test_case_1():\n",
    "    \"\"\"\n",
    "    Test Gradient Descent using numeric inputs and fixed gradients.\n",
    "    \"\"\"\n",
    "    x_values = np.array([5.0, 3.0, -1.0])\n",
    "    gradients = np.array([10.0, 6.0, -2.0])  \n",
    "\n",
    "    gd = GradientDescent(learning_rate=0.1, max_iter=3, tolerance=1e-6)\n",
    "    updated_values = []\n",
    "\n",
    "    for x, grad in zip(x_values, gradients):\n",
    "        updated_value = x - gd.learning_rate * grad\n",
    "        updated_values.append(updated_value)\n",
    "\n",
    "    expected_values = np.array([4.0, 2.4, -0.8])  \n",
    "    assert np.allclose(updated_values, expected_values, atol=1e-3), f\"Expected {expected_values}, got {updated_values}\"\n",
    "\n",
    "\n",
    "def test_case_2():\n",
    "    \"\"\"\n",
    "    Test Gradient Descent on a small set of numeric data points to ensure convergence.\n",
    "    \"\"\"\n",
    "    data_points = np.array([1.0, 2.0, 3.0, 4.0])\n",
    "    gradients = np.array([0.5, 1.0, 1.5, 2.0])\n",
    "\n",
    "    gd = GradientDescent(learning_rate=0.2, max_iter=1, tolerance=1e-6)\n",
    "    updated_points = data_points - gd.learning_rate * gradients\n",
    "\n",
    "    expected_points = np.array([0.9, 1.8, 2.7, 3.6])\n",
    "    assert np.allclose(updated_points, expected_points, atol=1e-3), f\"Expected {expected_points}, got {updated_points}\"\n",
    "\n",
    "\n",
    "def test_case_3():\n",
    "    \"\"\"\n",
    "    Test Gradient Descent with zero gradients to ensure no update occurs.\n",
    "    \"\"\"\n",
    "    x_values = np.array([4.0, -3.0, 7.0])\n",
    "    gradients = np.array([0.0, 0.0, 0.0])  \n",
    "\n",
    "    gd = GradientDescent(learning_rate=0.1, max_iter=3, tolerance=1e-6)\n",
    "    updated_values = []\n",
    "\n",
    "    for x, grad in zip(x_values, gradients):\n",
    "        updated_value = x - gd.learning_rate * grad\n",
    "        updated_values.append(updated_value)\n",
    "\n",
    "    expected_values = np.array([4.0, -3.0, 7.0])  # Should remain unchanged\n",
    "    assert np.allclose(updated_values, expected_values, atol=1e-3), f\"Expected {expected_values}, got {updated_values}\"\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def test_cases():\n",
    "    \"\"\"\n",
    "    Executes all Gradient Descent test cases.\n",
    "    \"\"\"\n",
    "    test_case_1()\n",
    "    test_case_2()\n",
    "    test_case_3()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee0a8e8-413b-4fdc-ac63-d36e6029b96c",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6318522d-520d-43cc-bfd5-35188ef234eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m================================================= test session starts =================================================\u001b[0m\n",
      "platform win32 -- Python 3.12.4, pytest-7.4.4, pluggy-1.0.0 -- C:\\Users\\ste7m\\anaconda3\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: C:\\Users\\ste7m\\Desktop\\DATA 2060\\DATA2060_GradientBoosted_DecisionTreeClassifier\\src\n",
      "plugins: anyio-4.2.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 0 items\n",
      "\n",
      "\u001b[33m================================================ \u001b[33mno tests ran\u001b[0m\u001b[33m in 0.03s\u001b[0m\u001b[33m ================================================\u001b[0m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'GradientDescent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     28\u001b[0m     pytest\u001b[38;5;241m.\u001b[39mmain([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-v\u001b[39m\u001b[38;5;124m\"\u001b[39m])  \n\u001b[1;32m---> 29\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m x_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m5.0\u001b[39m, \u001b[38;5;241m10.0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2.0\u001b[39m, \u001b[38;5;241m8.0\u001b[39m])\n\u001b[0;32m      7\u001b[0m gradient_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m2.0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m1.5\u001b[39m])\n\u001b[1;32m----> 9\u001b[0m gd \u001b[38;5;241m=\u001b[39m GradientDescent(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitial Data:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX Values: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_data\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GradientDescent' is not defined"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Reads input data, initializes Gradient Descent, and prints the results.\n",
    "    \"\"\"\n",
    "    # Example Input Data\n",
    "    x_data = np.array([5.0, 10.0, -2.0, 8.0])\n",
    "    gradient_data = np.array([1.0, 2.0, -0.5, 1.5])\n",
    "\n",
    "    gd = GradientDescent(learning_rate=0.1, max_iter=10, tolerance=1e-6)\n",
    "\n",
    "    print(\"Initial Data:\")\n",
    "    print(f\"X Values: {x_data}\")\n",
    "    print(f\"Gradients: {gradient_data}\")\n",
    "\n",
    "    print(\"\\nRunning Gradient Descent Updates:\")\n",
    "    updated_values = []\n",
    "\n",
    "    for x, grad in zip(x_data, gradient_data):\n",
    "        updated_value = x - gd.learning_rate * grad\n",
    "        updated_values.append(updated_value)\n",
    "        print(f\"Value: {x} -> Updated: {updated_value} (Gradient: {grad})\")\n",
    "\n",
    "    print(\"\\nFinal Results:\")\n",
    "    print(f\"Updated Values: {updated_values}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pytest.main([\"-v\"])  \n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1302c7-a9de-449e-975a-5f63d97c2b29",
   "metadata": {},
   "source": [
    "### Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36715f87-433a-4000-ad68-1bb3f3b251c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    " \n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    " \n",
    "# Divide the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Create a CART template\n",
    "tree_classifier = DecisionTreeClassifier(random_state=42)\n",
    " \n",
    "#Train the model on the training data\n",
    "tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions on test data\n",
    "y_pred = tree_classifier.predict(X_test)\n",
    " \n",
    "#Calculate the accuracy of the model<code>\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Model accuracy:\", accuracy)\n",
    " \n",
    "#View the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=tree_classifier.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=tree_classifier.classes_)\n",
    "disp.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599631ee-3240-4cd4-999d-0aa2ea839b10",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afa61e3-ca21-4210-bdb5-540b2131f4c5",
   "metadata": {},
   "source": [
    "[1] Friedman, J.H., 2001. Greedy function approximation: A gradient boosting machine. Annals of Statistics, pp. 11891232.\n",
    "\n",
    "[2] Scikit-learn, 2024. sklearn.ensemble.GradientBoostingClassifier. [online] Available at: https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html [Accessed: 2024-12-15].\n",
    "\n",
    "[3] Hastie, T., Tibshirani, R. and Friedman, J., 2009. The Elements of Statistical Learning. 2nd ed. Springer.\n",
    "\n",
    "[4] Ye, A., 2020. XGBoost, LightGBM, and Other Kaggle Competition Favorites: An Intuitive Explanation and Exploration. Analytics Vidhya, [online] 27 Sep. Available at: [https://medium.com/analytics-vidhya/xgboost-lightgbm-and-other-kaggle-competition-favorites-6212e8b0e835] [Accessed: 2024-12-15].\n",
    "\n",
    "[5] Ke, G., Meng, Q., Finley, T., Wang, T., Chen, W., Ma, W., Ye, Q., & Liu, T.-Y., 2017. LightGBM: A Highly Efficient Gradient Boosting Decision Tree. Microsoft Research, Peking University, and Microsoft Redmond. Available at: [https://dl.acm.org/doi/10.5555/3294996.3295074] [Accessed: 2024-12-15]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7979ccf-50b5-4ef5-a9a3-e590987dfcd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
