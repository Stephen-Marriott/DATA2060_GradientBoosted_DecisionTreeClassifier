{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39a08cff",
   "metadata": {},
   "source": [
    "### Loss Function and Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67e2e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "class GradientBoostedClassifier:\n",
    "    def __init__(self, n_trees=10, learning_rate=0.1):\n",
    "        self.n_trees = n_trees\n",
    "        self.learning_rate = learning_rate\n",
    "        self.trees = []\n",
    "        self.initial_prediction = None\n",
    "\n",
    "    def _log_odds(self, y):\n",
    "        p = np.mean(y)\n",
    "        return np.log(p / (1 - p))\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def loss(self, y, preds):\n",
    "        preds = np.clip(preds, 1e-15, 1 - 1e-15)\n",
    "        return -np.mean(y * np.log(preds) + (1 - y) * np.log(1 - preds))\n",
    "\n",
    "    def train(self, X, y):\n",
    "        self.initial_prediction = self._log_odds(y)\n",
    "        F = np.full(y.shape, self.initial_prediction)\n",
    "\n",
    "        for i in range(self.n_trees):\n",
    "            residuals = y - self._sigmoid(F)\n",
    "            tree = DecisionTreeRegressor(max_depth=3)\n",
    "            tree.fit(X, residuals)\n",
    "            F += self.learning_rate * tree.predict(X)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "        return F\n",
    "    \n",
    "    def predict(self, X):\n",
    "        F = np.full((X.shape[0],), self.initial_prediction)\n",
    "        for tree in self.trees:\n",
    "            F += self.learning_rate * tree.predict(X)\n",
    "        return self._sigmoid(F)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02c34f8",
   "metadata": {},
   "source": [
    "### Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "712405ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loss():\n",
    "    model = GradientBoostedClassifier()\n",
    "    y = np.array([0, 1, 1, 0])\n",
    "    preds = np.array([0.1, 0.9, 0.8, 0.2])\n",
    "    expected_loss = -np.mean(y * np.log(preds) + (1 - y) * np.log(1 - preds))\n",
    "    loss_value = model.loss(y, preds)\n",
    "    if np.isclose(loss_value, expected_loss):\n",
    "        print(\"Loss function test passed!\")\n",
    "    else:\n",
    "        raise ValueError(f\"Loss function test failed! Expected: {expected_loss}, Got: {loss_value}\")\n",
    "\n",
    "\n",
    "def test_train():\n",
    "    X = np.array([[1], [2], [3], [4]])\n",
    "    y = np.array([0, 1, 1, 0])\n",
    "    model = GradientBoostedClassifier(n_trees=2, learning_rate=0.1)\n",
    "    model.train(X, y)\n",
    "    preds = model.predict(X)\n",
    "    if len(model.trees) == 2 and preds.shape == y.shape:\n",
    "        print(\"Training test passed!\")\n",
    "    else:\n",
    "        raise ValueError(f\"Training test failed! Trees: {len(model.trees)}, Predictions shape: {preds.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c609048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Python_3_12_5)",
   "language": "python",
   "name": "python_3_12_5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
